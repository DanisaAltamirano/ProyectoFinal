# -*- coding: utf-8 -*-
"""Entregable.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15EqCJHpFLkkfD7Zs3Omj3gBz-a2CD4Yy
"""

import requests
import pandas as pd
import psycopg2



url = "https://api.frankfurter.app/latest"

# Realizar la solicitud GET
response = requests.get(url)

# Verificar si la solicitud fue exitosa (código de estado 200)
if response.status_code == 200:
    # Convertir los datos JSON a un DataFrame de pandas
    data = response.json()
    rates_data = data.get("rates", {})

    # Crear un DataFrame con una sola fila usando el índice "base"
    df = pd.DataFrame([rates_data], index=[data["base"]])

    # Agregar una columna con la fecha de última actualización
    df["LastUpdated"] = pd.to_datetime(data["date"])

    # Transponer el DataFrame para tener monedas como columnas
    df = df.T.reset_index()

    # Renombrar las columnas después de la transposición
    df.columns = ["Currency", "Exchange"]

    # Agregar la columna de fecha al final del DataFrame
    df["LastUpdated"] = pd.to_datetime(data["date"])

    # Filtrar por un periodo específico (ejemplo: últimos 7 días)
    start_date = pd.to_datetime('today') - pd.DateOffset(days=10)
    filtered_df = df[df["LastUpdated"] >= start_date]

    # Agregar una columna de ID incremental
    df["ID"] = range(1, len(df) + 1)

     # Eliminar la última fila que contiene información sobre la última actualización
    df = df.iloc[:-1]

    # Reorganizar el orden de las columnas
    df = df[["ID", "Currency", "Exchange", "LastUpdated"]]

    # Imprimir el DataFrame
    print(df)
else:
    print(f"Error en la solicitud. Código de estado: {response.status_code}")

from os import environ as env
from psycopg2 import connect
from pyspark.sql import SparkSession
import pandas as pd
from dotenv import load_dotenv
from sqlalchemy import create_engine

# Cargar variables de entorno desde el archivo .env
load_dotenv()

# Variables de configuración de Redshift
REDSHIFT_HOST = env["REDSHIFT_HOST"]
REDSHIFT_PORT = env["REDSHIFT_PORT"]
REDSHIFT_DB = env["REDSHIFT_DB"]
REDSHIFT_USER = env["REDSHIFT_USER"]
REDSHIFT_PASSWORD = env["REDSHIFT_PASSWORD"]
REDSHIFT_SCHEMA= env["REDSHIFT_SCHEMA"]
REDSHIFT_URL = f"jdbc:postgresql://{REDSHIFT_HOST}:{REDSHIFT_PORT}/{REDSHIFT_DB}?user={REDSHIFT_USER}&password={REDSHIFT_PASSWORD}"

# Cadena de conexión
cadena_conexion = f"host={REDSHIFT_HOST} port={REDSHIFT_PORT} dbname={REDSHIFT_DB} user={REDSHIFT_USER} password={REDSHIFT_PASSWORD} options='-c search_path={REDSHIFT_SCHEMA}'"

# Intentar establecer la conexión
try:
    # Establecer la conexión
    conexion = psycopg2.connect(cadena_conexion)

    # Crear un cursor para ejecutar la consulta
    cursor = conexion.cursor()

    # Imprimir mensaje de éxito
    print("Conexión a Redshift establecida correctamente.")

    # Cerrar el cursor y la conexión
    cursor.close()
    conexion.close()

except Exception as e:
    print(f"Error al conectar a Redshift: {e}")
    # Puedes imprimir detalles adicionales del error si es necesario


# Comando SQL para eliminar la tabla si existe
drop_table_sql = f"DROP TABLE IF EXISTS {REDSHIFT_SCHEMA}.CurrencyExchange;"


 # Definición de la tabla
tabla_sql = f"""
    CREATE TABLE {REDSHIFT_SCHEMA}.CurrencyExchange(
        ID INT PRIMARY KEY,
        Currency VARCHAR(50) NOT NULL,
        exchange DECIMAL(10, 2) NOT NULL,
        LastUpdated DATE
    );
"""   

try:
    # Establecer la conexión
    conexion = psycopg2.connect(cadena_conexion)

    # Crear un cursor para ejecutar la consulta
    cursor = conexion.cursor()

    # Eliminar la tabla si existe
    cursor.execute(f"DROP TABLE IF EXISTS {REDSHIFT_SCHEMA}.CurrencyExchange")

    # Ejecutar la consulta CREATE TABLE
    cursor.execute(tabla_sql)

    # Confirmar la transacción
    conexion.commit()

    
    # Imprimir mensaje de éxito
    print("Tabla eliminada (si existía) y creada nuevamente correctamente.")

except Exception as e:
    print(f"Error al conectar a Redshift o al eliminar/crear la tabla: {e}")

    # Cerrar el cursor y la conexión
    cursor.close()
    conexion.close()

import psycopg2
from sqlalchemy import create_engine

# Nombre de la tabla en Redshift
nombre_tabla = 'currencyexchange'

# Intentar cargar los datos en la tabla
try:
    # Establecer la conexión
    conexion = psycopg2.connect(cadena_conexion)

    # Utilizar to_sql para cargar el DataFrame en la tabla
    cursor = conexion.cursor()

    # Crear una cadena de inserción de datos
    columns = ",".join(df.columns)
    values_template = ",".join(["%s"] * len(df.columns))
    query = f"INSERT INTO {REDSHIFT_SCHEMA}.{nombre_tabla} ({columns}) VALUES ({values_template})"

    # Convertir la columna 'LastUpdated' a formato de fecha
    df['LastUpdated'] = pd.to_datetime(df['LastUpdated']).dt.date

    # Convertir la columna 'LastUpdated' a formato de fecha y hora
    #df['LastUpdated'] = pd.to_datetime(df['LastUpdated']).dt.strftime('%Y-%m-%d %H:%M:%S')

    # Ejecutar la consulta para cada fila
    for _, row in df.iterrows():
        cursor.execute(query, tuple(row))

    # Confirmar la transacción
    conexion.commit()

    # Imprimir mensaje de éxito
    print(f'Datos insertados en la tabla {REDSHIFT_SCHEMA}.{nombre_tabla} correctamente.')

except Exception as e:
    print(f"Error al conectar a Redshift o al insertar datos en la tabla: {e}")
    # Puedes imprimir detalles adicionales del error si es necesario
finally:
    # Cerrar la conexión
    if conexion:
        conexion.close()